{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d317148a-aec5-4490-a9d7-43d06e7fd200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3815ec77-8b43-4414-a6bc-4cca5c7c69ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV: 4.13.0\n",
      "PyTorch: 2.2.2\n",
      "CUDA available: True\n",
      "MediaPipe: 0.10.9\n",
      "NumPy: 1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(f\"OpenCV: {cv2.__version__}\")\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"MediaPipe: {mp.__version__}\")\n",
    "print(f\"NumPy: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e2f5c99-402b-411f-b6e1-924d5c7b639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# print(\"Press 'q' to quit\")\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#     results = face_mesh.process(rgb_frame)\n",
    "    \n",
    "#     # Draw landmarks if face detected\n",
    "#     if results.multi_face_landmarks:\n",
    "#         for face_landmarks in results.multi_face_landmarks:\n",
    "#             mp_drawing.draw_landmarks(\n",
    "#                 image=frame,\n",
    "#                 landmark_list=face_landmarks,\n",
    "#                 connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "#                 landmark_drawing_spec=None,\n",
    "#                 connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "#             )\n",
    "        \n",
    "#         # Display status\n",
    "#         cv2.putText(frame, \"Face Detected\", (10, 30),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "#     else:\n",
    "#         cv2.putText(frame, \"No Face\", (10, 30),\n",
    "#                     cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "#     cv2.imshow('MediaPipe FaceMesh', frame)\n",
    "    \n",
    "#     if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "# face_mesh.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d79479a-a111-4c90-8407-39a9ed4d6c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eye landmark indices\n",
    "LEFT_EYE = [33, 160, 158, 133, 153, 144]\n",
    "RIGHT_EYE = [362, 385, 387, 263, 373, 380]\n",
    "\n",
    "# 3D model points for head pose\n",
    "MODEL_POINTS = np.array([\n",
    "    (0.0, 0.0, 0.0),\n",
    "    (0.0, -330.0, -65.0),\n",
    "    (-225.0, 170.0, -135.0),\n",
    "    (225.0, 170.0, -135.0),\n",
    "    (-150.0, -150.0, -125.0),\n",
    "    (150.0, -150.0, -125.0)\n",
    "], dtype=np.float64)\n",
    "\n",
    "# Thresholds\n",
    "EAR_THRESHOLD = 0.25\n",
    "YAW_THRESHOLD = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a53ac890-1fc7-488f-99aa-d34717d20607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(point1, point2):\n",
    "    return np.sqrt((point1.x - point2.x)**2 + (point1.y - point2.y)**2)\n",
    "\n",
    "def calculate_ear(eye_landmarks):\n",
    "    vertical1 = calculate_distance(eye_landmarks[1], eye_landmarks[5])\n",
    "    vertical2 = calculate_distance(eye_landmarks[2], eye_landmarks[4])\n",
    "    horizontal = calculate_distance(eye_landmarks[0], eye_landmarks[3])\n",
    "    ear = (vertical1 + vertical2) / (2.0 * horizontal)\n",
    "    return ear\n",
    "\n",
    "def get_eye_landmarks(face_landmarks, eye_indices):\n",
    "    return [face_landmarks.landmark[i] for i in eye_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22845494-4d42-4d8c-a036-3e2733243460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_points(face_landmarks, img_width, img_height):\n",
    "    indices = [1, 152, 33, 263, 61, 291]\n",
    "    points_2d = []\n",
    "    for idx in indices:\n",
    "        landmark = face_landmarks.landmark[idx]\n",
    "        x = int(landmark.x * img_width)\n",
    "        y = int(landmark.y * img_height)\n",
    "        points_2d.append([x, y])\n",
    "    return np.array(points_2d, dtype=np.float64)\n",
    "\n",
    "def get_head_pose(face_landmarks, img_width, img_height):\n",
    "    image_points = get_2d_points(face_landmarks, img_width, img_height)\n",
    "    \n",
    "    focal_length = img_width\n",
    "    center = (img_width / 2, img_height / 2)\n",
    "    camera_matrix = np.array([\n",
    "        [focal_length, 0, center[0]],\n",
    "        [0, focal_length, center[1]],\n",
    "        [0, 0, 1]\n",
    "    ], dtype=np.float64)\n",
    "    \n",
    "    dist_coeffs = np.zeros((4, 1))\n",
    "    \n",
    "    success, rotation_vector, translation_vector = cv2.solvePnP(\n",
    "        MODEL_POINTS,\n",
    "        image_points,\n",
    "        camera_matrix,\n",
    "        dist_coeffs,\n",
    "        flags=cv2.SOLVEPNP_ITERATIVE\n",
    "    )\n",
    "    \n",
    "    rotation_matrix, _ = cv2.Rodrigues(rotation_vector)\n",
    "    pose_matrix = cv2.hconcat((rotation_matrix, translation_vector))\n",
    "    _, _, _, _, _, _, euler_angles = cv2.decomposeProjectionMatrix(pose_matrix)\n",
    "    \n",
    "    pitch = euler_angles[0][0]\n",
    "    yaw = euler_angles[1][0]\n",
    "    roll = euler_angles[2][0]\n",
    "    \n",
    "    return pitch, yaw, roll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca320355-a79d-42a5-bce8-9e83d1782207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models initialized!\n"
     ]
    }
   ],
   "source": [
    "# Initialize YOLO\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Initialize MediaPipe\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "face_mesh = mp_face_mesh.FaceMesh(\n",
    "    static_image_mode=False,\n",
    "    max_num_faces=1,\n",
    "    refine_landmarks=True,\n",
    "    min_detection_confidence=0.5,\n",
    "    min_tracking_confidence=0.5\n",
    ")\n",
    "\n",
    "print(\"Models initialized!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c8ca002-8d73-40b1-ba01-f5213cf797b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Press 'q' to quit\n",
      "\n",
      "0: 480x640 1 person, 22.6ms\n",
      "Speed: 40.5ms preprocess, 22.6ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 2.8ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 1.5ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.8ms\n",
      "Speed: 1.8ms preprocess, 15.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 1.5ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.6ms\n",
      "Speed: 1.2ms preprocess, 16.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 1.3ms preprocess, 13.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.9ms\n",
      "Speed: 1.3ms preprocess, 14.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.5ms\n",
      "Speed: 1.7ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.1ms\n",
      "Speed: 2.5ms preprocess, 18.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 1.4ms preprocess, 14.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 1.7ms preprocess, 14.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.1ms\n",
      "Speed: 1.2ms preprocess, 14.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 1.5ms preprocess, 14.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 1.5ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.0ms\n",
      "Speed: 1.4ms preprocess, 15.0ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 2.1ms preprocess, 14.6ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 1.3ms preprocess, 16.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.8ms\n",
      "Speed: 1.3ms preprocess, 15.8ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 1.3ms preprocess, 14.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.1ms\n",
      "Speed: 1.2ms preprocess, 14.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.5ms\n",
      "Speed: 1.6ms preprocess, 19.5ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 1.2ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.0ms\n",
      "Speed: 1.7ms preprocess, 17.0ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 1.6ms preprocess, 14.7ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.0ms\n",
      "Speed: 1.5ms preprocess, 15.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.4ms\n",
      "Speed: 2.1ms preprocess, 17.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.8ms\n",
      "Speed: 1.8ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 2.1ms preprocess, 13.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.4ms\n",
      "Speed: 1.5ms preprocess, 13.4ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 1.8ms preprocess, 14.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.0ms\n",
      "Speed: 1.5ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.4ms\n",
      "Speed: 1.8ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 1.3ms preprocess, 13.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 1.4ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.1ms\n",
      "Speed: 1.9ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 1.6ms preprocess, 14.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 22.3ms\n",
      "Speed: 1.5ms preprocess, 22.3ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.0ms\n",
      "Speed: 2.1ms preprocess, 17.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.3ms\n",
      "Speed: 1.7ms preprocess, 15.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 1.8ms preprocess, 14.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 1.6ms preprocess, 14.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 1.8ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.7ms\n",
      "Speed: 2.1ms preprocess, 18.7ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.4ms\n",
      "Speed: 2.0ms preprocess, 16.4ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 1.3ms preprocess, 14.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.1ms\n",
      "Speed: 1.8ms preprocess, 14.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.4ms\n",
      "Speed: 2.3ms preprocess, 19.4ms inference, 4.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.4ms\n",
      "Speed: 2.1ms preprocess, 15.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 1.7ms preprocess, 17.3ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.2ms\n",
      "Speed: 2.2ms preprocess, 18.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.8ms\n",
      "Speed: 2.3ms preprocess, 20.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.7ms\n",
      "Speed: 1.7ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.0ms\n",
      "Speed: 2.4ms preprocess, 19.0ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 1.7ms preprocess, 17.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.6ms\n",
      "Speed: 2.4ms preprocess, 14.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.0ms\n",
      "Speed: 1.4ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 1.7ms preprocess, 13.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 2.1ms preprocess, 13.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.3ms\n",
      "Speed: 1.9ms preprocess, 15.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.7ms\n",
      "Speed: 2.1ms preprocess, 15.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.7ms\n",
      "Speed: 1.8ms preprocess, 12.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.4ms\n",
      "Speed: 1.7ms preprocess, 13.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 20.4ms\n",
      "Speed: 2.2ms preprocess, 20.4ms inference, 6.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 25.6ms\n",
      "Speed: 2.1ms preprocess, 25.6ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.2ms\n",
      "Speed: 1.6ms preprocess, 15.2ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.5ms\n",
      "Speed: 2.1ms preprocess, 14.5ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 2.5ms preprocess, 13.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.8ms\n",
      "Speed: 2.1ms preprocess, 16.8ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 3.3ms preprocess, 13.6ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 2.1ms preprocess, 17.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 1.9ms preprocess, 14.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 2.1ms preprocess, 14.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.8ms\n",
      "Speed: 2.1ms preprocess, 13.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.7ms\n",
      "Speed: 1.9ms preprocess, 12.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.1ms\n",
      "Speed: 2.8ms preprocess, 19.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 1.9ms preprocess, 16.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.3ms\n",
      "Speed: 3.7ms preprocess, 15.3ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.0ms\n",
      "Speed: 1.9ms preprocess, 16.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.1ms\n",
      "Speed: 2.4ms preprocess, 15.1ms inference, 5.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 2.0ms preprocess, 16.9ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.7ms\n",
      "Speed: 2.4ms preprocess, 17.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.7ms\n",
      "Speed: 2.6ms preprocess, 15.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.1ms\n",
      "Speed: 2.0ms preprocess, 17.1ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 2.0ms preprocess, 14.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 2.2ms preprocess, 13.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.2ms\n",
      "Speed: 2.1ms preprocess, 14.2ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.7ms\n",
      "Speed: 2.2ms preprocess, 15.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.2ms\n",
      "Speed: 2.4ms preprocess, 16.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.6ms\n",
      "Speed: 2.2ms preprocess, 13.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 2.3ms preprocess, 14.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.4ms\n",
      "Speed: 1.9ms preprocess, 16.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.1ms\n",
      "Speed: 2.1ms preprocess, 14.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.6ms\n",
      "Speed: 2.0ms preprocess, 15.6ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.5ms\n",
      "Speed: 4.5ms preprocess, 15.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.1ms\n",
      "Speed: 3.0ms preprocess, 16.1ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.5ms\n",
      "Speed: 2.4ms preprocess, 12.5ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 22.9ms\n",
      "Speed: 1.8ms preprocess, 22.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 2.1ms preprocess, 13.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.8ms\n",
      "Speed: 2.5ms preprocess, 16.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 18.7ms\n",
      "Speed: 2.0ms preprocess, 18.7ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.9ms\n",
      "Speed: 2.6ms preprocess, 15.9ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.9ms\n",
      "Speed: 1.7ms preprocess, 14.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 3.1ms preprocess, 13.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.2ms\n",
      "Speed: 3.8ms preprocess, 13.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.3ms\n",
      "Speed: 2.4ms preprocess, 17.3ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.8ms\n",
      "Speed: 2.7ms preprocess, 15.8ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.5ms\n",
      "Speed: 2.6ms preprocess, 17.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.4ms\n",
      "Speed: 1.8ms preprocess, 15.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.4ms\n",
      "Speed: 1.9ms preprocess, 12.4ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 2.5ms preprocess, 13.9ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.8ms\n",
      "Speed: 4.6ms preprocess, 12.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 3.1ms preprocess, 13.9ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.7ms\n",
      "Speed: 4.1ms preprocess, 12.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 12.8ms\n",
      "Speed: 1.8ms preprocess, 12.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.5ms\n",
      "Speed: 2.3ms preprocess, 16.5ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.8ms\n",
      "Speed: 2.7ms preprocess, 13.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.9ms\n",
      "Speed: 2.3ms preprocess, 13.9ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 4.2ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 2.4ms preprocess, 13.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.9ms\n",
      "Speed: 2.5ms preprocess, 16.9ms inference, 5.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 19.8ms\n",
      "Speed: 1.9ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.4ms\n",
      "Speed: 2.5ms preprocess, 13.4ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 2.2ms preprocess, 13.7ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 16.5ms\n",
      "Speed: 2.1ms preprocess, 16.5ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 2.2ms preprocess, 14.3ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 4.2ms preprocess, 14.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.8ms\n",
      "Speed: 2.7ms preprocess, 13.8ms inference, 4.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.7ms\n",
      "Speed: 2.3ms preprocess, 14.7ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.5ms\n",
      "Speed: 1.8ms preprocess, 14.5ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.3ms\n",
      "Speed: 2.0ms preprocess, 14.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.0ms\n",
      "Speed: 2.3ms preprocess, 17.0ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.8ms\n",
      "Speed: 2.9ms preprocess, 15.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.5ms\n",
      "Speed: 2.4ms preprocess, 13.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.4ms\n",
      "Speed: 2.8ms preprocess, 13.4ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.5ms\n",
      "Speed: 2.2ms preprocess, 14.5ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.9ms\n",
      "Speed: 2.3ms preprocess, 14.9ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.4ms\n",
      "Speed: 2.0ms preprocess, 14.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 17.8ms\n",
      "Speed: 3.1ms preprocess, 17.8ms inference, 6.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.7ms\n",
      "Speed: 5.2ms preprocess, 13.7ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 15.3ms\n",
      "Speed: 3.8ms preprocess, 15.3ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.0ms\n",
      "Speed: 2.1ms preprocess, 14.0ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 13.1ms\n",
      "Speed: 2.1ms preprocess, 13.1ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.8ms\n",
      "Speed: 1.9ms preprocess, 14.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 person, 14.5ms\n",
      "Speed: 2.5ms preprocess, 14.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    img_height, img_width = frame.shape[:2]\n",
    "    \n",
    "    # YOLO Detection\n",
    "    yolo_results = model(frame)\n",
    "    phone_detected = False\n",
    "    for box in yolo_results[0].boxes:\n",
    "        if int(box.cls[0]) == 67 and float(box.conf[0]) > 0.4:\n",
    "            phone_detected = True\n",
    "            break\n",
    "    \n",
    "    # MediaPipe Face Detection\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    face_results = face_mesh.process(rgb_frame)\n",
    "    face_detected = face_results.multi_face_landmarks is not None\n",
    "    \n",
    "    # Draw YOLO\n",
    "    annotated_frame = yolo_results[0].plot()\n",
    "    \n",
    "    # Process face\n",
    "    if face_detected:\n",
    "        face_landmarks = face_results.multi_face_landmarks[0]\n",
    "        \n",
    "        # Draw mesh\n",
    "        mp_drawing.draw_landmarks(\n",
    "            image=annotated_frame,\n",
    "            landmark_list=face_landmarks,\n",
    "            connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
    "            landmark_drawing_spec=None,\n",
    "            connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style()\n",
    "        )\n",
    "        \n",
    "        # Calculate EAR\n",
    "        left_eye = get_eye_landmarks(face_landmarks, LEFT_EYE)\n",
    "        right_eye = get_eye_landmarks(face_landmarks, RIGHT_EYE)\n",
    "        left_ear = calculate_ear(left_eye)\n",
    "        right_ear = calculate_ear(right_eye)\n",
    "        avg_ear = (left_ear + right_ear) / 2.0\n",
    "        eyes_closed = avg_ear < EAR_THRESHOLD\n",
    "        \n",
    "        # Calculate head pose\n",
    "        pitch, yaw, roll = get_head_pose(face_landmarks, img_width, img_height)\n",
    "        looking_away = abs(yaw) > YAW_THRESHOLD\n",
    "        \n",
    "        # Display EAR\n",
    "        ear_text = f\"EAR: {avg_ear:.3f}\"\n",
    "        ear_color = (0, 0, 255) if eyes_closed else (0, 255, 0)\n",
    "        cv2.putText(annotated_frame, ear_text, (10, 100),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, ear_color, 2)\n",
    "        \n",
    "        blink_text = \"EYES CLOSED\" if eyes_closed else \"EYES OPEN\"\n",
    "        cv2.putText(annotated_frame, blink_text, (10, 135),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, ear_color, 2)\n",
    "        \n",
    "        # Display head pose\n",
    "        pose_text = f\"Yaw: {yaw:.1f}deg Pitch: {pitch:.1f}deg\"\n",
    "        cv2.putText(annotated_frame, pose_text, (10, 170),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "        \n",
    "        gaze_color = (0, 0, 255) if looking_away else (0, 255, 0)\n",
    "        gaze_text = \"LOOKING AWAY\" if looking_away else \"LOOKING FORWARD\"\n",
    "        cv2.putText(annotated_frame, gaze_text, (10, 205),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, gaze_color, 2)\n",
    "    \n",
    "    # Display status\n",
    "    phone_color = (0, 0, 255) if phone_detected else (0, 255, 0)\n",
    "    phone_text = \"PHONE: YES\" if phone_detected else \"PHONE: NO\"\n",
    "    cv2.putText(annotated_frame, phone_text, (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, phone_color, 2)\n",
    "    \n",
    "    face_color = (0, 255, 0) if face_detected else (0, 0, 255)\n",
    "    face_text = \"FACE: YES\" if face_detected else \"FACE: NO\"\n",
    "    cv2.putText(annotated_frame, face_text, (10, 65),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, face_color, 2)\n",
    "    \n",
    "    cv2.imshow('Attention Detection', annotated_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "face_mesh.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
